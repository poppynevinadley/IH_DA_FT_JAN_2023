{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAS5MqM9xy-N"
   },
   "source": [
    "## Health Care for All Case Study using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:12:34.907886Z",
     "start_time": "2022-11-09T11:12:33.803894Z"
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1623063461098,
     "user": {
      "displayName": "Ignacio Soteras",
      "photoUrl": "",
      "userId": "02050793736257155229"
     },
     "user_tz": -120
    },
    "id": "DVtwE6bRxy-V"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "pd.options.display.max_rows = 50\n",
    "## Install xlrd package to load Excel files\n",
    "# conda install openpyxl\n",
    "## conda install xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAND_STATE = 34 # for reproducible shuffling\n",
    "TT_RATIO = 0.3 # test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "def remove_outliers(df):\n",
    "    for c in df.columns:\n",
    "            pct_75 = np.percentile(df[c], 75)\n",
    "            pct_25 = np.percentile(df[c], 25)\n",
    "            upper_bound = pct_75 + 1.5*iqr(df[c])\n",
    "            lower_bound = pct_25 - 1.5*iqr(df[c])\n",
    "            condition = (df[c] < upper_bound) & (df[c] > lower_bound)\n",
    "            df[c] = df[c][condition]  # Filter out the outliers\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> We begin by loading the precleaned data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:12:36.718597Z",
     "start_time": "2022-11-09T11:12:36.701312Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'hk_df_cleaned.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23340\\319403520.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhk_df\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hk_df_cleaned.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 678\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 575\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 932\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    933\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m             \u001b[1;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[1;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[0;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\Ananconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    784\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m\"b\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    785\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 786\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'hk_df_cleaned.csv'"
     ]
    }
   ],
   "source": [
    "hk_df= pd.read_csv(\"hk_df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:12:46.144229Z",
     "start_time": "2022-11-09T11:12:46.135839Z"
    }
   },
   "outputs": [],
   "source": [
    "hk_df.columns # inspect the column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> checking correlations between numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:12:58.086382Z",
     "start_time": "2022-11-09T11:12:52.505595Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(hk_df.select_dtypes(np.number)) # pairplot generates a grid of scatter plots for all numerical variables except on the diagonal where it displays distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:12:58.144465Z",
     "start_time": "2022-11-09T11:12:58.098437Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=hk_df['med_fam_income'], y=hk_df['avg_household_income'],c='g') # note the correlation between income sources\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> plotting the correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = hk_df.corr()\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True # trick to filter out the upper-right triangle, which is redundant due to symmetry\n",
    "with sns.axes_style(\"white\"):\n",
    "    f, ax = plt.subplots(figsize=(16, 14))\n",
    "    ax = sns.heatmap(corr, mask=mask,cmap='coolwarm', vmin=-1,vmax=1,annot=True, square=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> removing highly correlated columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:13:24.366115Z",
     "start_time": "2022-11-09T11:13:24.350446Z"
    }
   },
   "outputs": [],
   "source": [
    "CORR_THRESH = 0.80\n",
    "corr_matrix=hk_df.corr().abs()\n",
    "upper_triangle=corr_matrix.where(np.triu(np.ones(corr_matrix.shape),k=1).astype(bool))\n",
    "corrd_cols = [column for column in upper_triangle.columns if any(upper_triangle[column] > CORR_THRESH)]\n",
    "hk_df.drop(corrd_cols,axis=1,inplace=True)\n",
    "hk_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:13:33.293181Z",
     "start_time": "2022-11-09T11:13:33.028722Z"
    }
   },
   "outputs": [],
   "source": [
    "hk_df.hist(figsize=(11,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> distribution of home value is skewed towards lower incomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:13:35.079215Z",
     "start_time": "2022-11-09T11:13:34.988547Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.distplot((hk_df['median_home_val']), bins=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## X,y, one-hot, and test/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = hk_df.drop('target_d', axis=1)\n",
    "y = hk_df.target_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericalX = X.select_dtypes(np.number)\n",
    "categoricalX = X.select_dtypes(np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode the categorical features\n",
    "X = pd.concat([pd.get_dummies(X[categoricalX.columns],drop_first=True),\n",
    "               remove_outliers(X[numericalX.columns])],\n",
    "              axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_idcs = X[X.isna().any(axis=1)].index\n",
    "X = pd.DataFrame(X).drop(na_idcs)\n",
    "y = pd.DataFrame(y).drop(na_idcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TT_RATIO, random_state=RAND_STATE)\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## continuous transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Power Transformer: we use a power transformer to remove the skew and rescale the data to have zero mean and unit variance.  It improves modeling errors in linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:14:03.683606Z",
     "start_time": "2022-11-09T11:14:03.514315Z"
    }
   },
   "outputs": [],
   "source": [
    "pt = PowerTransformer()\n",
    "med_home_val_transformed=pt.fit_transform(hk_df['median_home_val'].to_numpy().reshape(-1,1))\n",
    "sns.displot(med_home_val_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:14:06.223650Z",
     "start_time": "2022-11-09T11:14:06.218077Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"the parameters used to transform median_home_val are\")\n",
    "pt.get_params(),pt.lambdas_ # parameter used in the power transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct = ColumnTransformer([(\"pt\", pt, list(numericalX.columns))],\n",
    "                        remainder='drop',verbose_feature_names_out=True,verbose=True).fit(X_train)\n",
    "X_train_ct = pd.DataFrame(ct.transform(X_train),columns=ct.get_feature_names_out())\n",
    "X_test_ct = pd.DataFrame(ct.transform(X_test),columns=ct.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train_ct)\n",
    "X_test_ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_const_ct = sm.add_constant(X_train_ct.to_numpy()) # adding a constant\n",
    "\n",
    "model = sm.OLS(y_train, X_train_const_ct).fit() #this finds the beta and the coefficient - the paremeters \n",
    "predictions_train = model.predict(X_train_const_ct)\n",
    "\n",
    "X_test_const_ct = sm.add_constant(X_test_ct) # adding a constant\n",
    "predictions_test = model.predict(X_test_const_ct)\n",
    "print_model = model.summary()  #always scale after both splits - which equals fitting models but not include data from test \n",
    "#set, okay so use train set for scaling, \n",
    "#only transforming \n",
    "#no scaling or transforming target variable or Y, \n",
    "#so use train test for test set not test set scaling \n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Two options for OneHot Encoding\n",
    "# get dummies pandas\n",
    "categoricals_features=pd.get_dummies(categoricals_features, drop_first=True)\n",
    "\n",
    "##pd.DataFrame(OneHotEncoder(drop='first').fit_transform(categoricals_features).toarray(),\n",
    "## ##columns=OneHotEncoder(drop='first').fit(categoricals_features).get_feature_names(input_features=categoricals_feature##s.columns)).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ";'#### Scikit Learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:10.798071Z",
     "start_time": "2022-11-09T11:42:10.783876Z"
    }
   },
   "outputs": [],
   "source": [
    "model=LinearRegression()    # model\n",
    "model.fit(X_train_ct, y_train)   # model train - need to check r squared for the train - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:13.354450Z",
     "start_time": "2022-11-09T11:42:13.345778Z"
    }
   },
   "outputs": [],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:13.692702Z",
     "start_time": "2022-11-09T11:42:13.685216Z"
    }
   },
   "outputs": [],
   "source": [
    "model.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:20.166074Z",
     "start_time": "2022-11-09T11:42:20.162016Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = pd.DataFrame(model.predict(X_test_ct),columns = ['target_d'] )      # model prediction\n",
    "y_pred_train =  pd.DataFrame(model.predict(X_train_ct),columns = ['target_d'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:24.999916Z",
     "start_time": "2022-11-09T11:42:24.995223Z"
    }
   },
   "outputs": [],
   "source": [
    "result=pd.DataFrame({\"y_test\": list(y_test),\"y_pred\": list(y_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:42:35.767453Z",
     "start_time": "2022-11-09T11:42:35.610586Z"
    }
   },
   "outputs": [],
   "source": [
    "# Make an scatter plot y_pred vs y\n",
    "# What kind of plot you will get if all the all the predictions are ok?\n",
    "# A stright line\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(14,4))\n",
    "ax[0].plot(y_pred, y_test, 'o')\n",
    "ax[0].set_xlabel(\"y_test\")\n",
    "ax[0].set_ylabel(\"y_pred\")\n",
    "ax[0].set_title(\"Test Set -Predicted vs real\")\n",
    "\n",
    "# Get a histogram of the residuals ie: y - y_pred.  Homoscdasticity\n",
    "# It resembles a normal distribution?\n",
    "ax[1].hist(y_test - y_pred)\n",
    "ax[1].set_xlabel(\"Test y-y_pred\")\n",
    "ax[1].set_title(\"Test Set Residual histogram\")\n",
    "\n",
    "ax[2].plot(y_pred,y_pred.to_numpy()-y_test.to_numpy(),\"o\")\n",
    "ax[2].set_xlabel(\"predited\")\n",
    "ax[2].set_ylabel(\"residuals\")\n",
    "ax[2].set_title(\"Residuals by Predicted\")\n",
    "ax[2].plot(y_pred,np.zeros(len(y_pred)),linestyle='dashed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>more fancy using seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:46:00.746250Z",
     "start_time": "2022-11-09T11:46:00.592500Z"
    }
   },
   "outputs": [],
   "source": [
    "yp_ = y_pred.to_numpy()\n",
    "yt_ = y_test.to_numpy()\n",
    "sns.regplot(yp_,yt_,scatter_kws={\"color\": \"red\"}, line_kws={\"color\": \"black\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:47:20.528419Z",
     "start_time": "2022-11-09T11:47:20.520728Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mse(y_test,y_pred)) #overfitting if r squared is much lower in train set than in test set\n",
    "print(mae(y_test,y_pred))\n",
    "##prediction on the train set\n",
    "print(mse(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:48:18.639564Z",
     "start_time": "2022-11-09T11:48:18.629757Z"
    }
   },
   "outputs": [],
   "source": [
    "R2=r2_score(y_test,y_pred) #only mainly on test set use as we want to know this\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:48:30.841778Z",
     "start_time": "2022-11-09T11:48:30.836396Z"
    }
   },
   "outputs": [],
   "source": [
    "R2_test=model.score(X_test_ct,y_test)\n",
    "R2_train=model.score(X_train_ct,y_train)\n",
    "Adj_R2= 1 - (1-R2)*(len(y_test)-1)/(len(y_test)-X_test.shape[1]-1)\n",
    "Adj_R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:49:34.566146Z",
     "start_time": "2022-11-09T11:49:34.556740Z"
    }
   },
   "outputs": [],
   "source": [
    "features_importances = pd.DataFrame(data={\n",
    "    'Attribute': X_train.columns,\n",
    "    'Importance': abs(model.coef_.reshape(len(X_train.columns),))\n",
    "})\n",
    "features_importances = features_importances.sort_values(by='Importance', ascending=False)\n",
    "features_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-09T11:53:35.952556Z",
     "start_time": "2022-11-09T11:53:35.859229Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.bar(x=features_importances['Attribute'].iloc[:10], height=features_importances['Importance'].iloc[:10], color='#087E8B')\n",
    "plt.title('Feature importance rankings', size=12)\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "sns.set_context('notebook')\n",
    "sns.color_palette(\"bright\")\n",
    "\n",
    "f, ax = plt.subplots(figsize=(18, 12))\n",
    "sns.despine(f, left=True, bottom=True)\n",
    "sns.barplot(x=\"state\", y=\"target_d\", data=hk_df, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hk_df.to_csv(\"Data/healthcare_for_all_transformed_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# why aren't we outputting the model coefficients to cvs. We already have the data!"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Intro to Pandas - \"Healthcare for All\" Code Along - Structure.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
